{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f3b86d-f142-4a7c-a96f-046b0e77ae6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745764697.535436   29619 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1 Pro\n",
      "Processing filtered_train:   0%|                         | 0/20 [00:00<?, ?it/s]W0000 00:00:1745764697.545491   52887 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745764697.553618   52887 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/again/nvaS2J5mcEk_030.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/again/gU5EI_ZTzxw_021.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/again/UI5KLVn8JKI_007.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:   5%|â–Š                | 1/20 [00:28<08:59, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/friend/YasOpK1RNvg_011.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/friend/pv1yeA4iHmU_016.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 5/20 [02:27<07:31, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/no/iHR2uV-Uxc8_021.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 6/20 [02:55<06:50, 29.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/milk/PvzBgEcEPew_035.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 9/20 [04:31<05:33, 30.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/eat/hUrfB8bikfw_024.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 10/20 [05:07<05:20, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/finish/3_lBaA2U6aY_022.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/finish/Vintf-DLWq0_027.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 12/20 [06:06<04:06, 30.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/what/_ZlZH4b0C44_025.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/20 [06:32<03:27, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/yes/q_p38s5JsXo_032.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/20 [07:32<02:28, 29.70s/it]OpenCV: Couldn't read video stream from file \"filtered_train/school/PsLiyUyrqds_003.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping unreadable video: filtered_train/school/PsLiyUyrqds_003.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"filtered_train/school/PsLiyUyrqds_004.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping unreadable video: filtered_train/school/PsLiyUyrqds_004.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 17/20 [08:30<01:28, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/fish/hUrfB8bikfw_028.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/fish/hUrfB8bikfw_027.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 18/20 [09:06<01:03, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/drink/OSPBKnsTuDY_012.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/drink/OSPBKnsTuDY_013.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 19/20 [09:37<00:31, 31.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_train/orange/xEw0KrlJA6Q_029.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_train/orange/NAZKMt2NhtU_020.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [10:06<00:00, 30.33s/it]\n",
      "Processing filtered_test:   0%|                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/again/nvaS2J5mcEk_030.mp4\n",
      "âš ï¸ Skipping incomplete/broken video: filtered_test/again/gU5EI_ZTzxw_021.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:   5%|â–‰                 | 1/20 [00:12<03:53, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/friend/iHR2uV-Uxc8_022.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 6/20 [01:11<02:49, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/milk/PvzBgEcEPew_035.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 9/20 [01:49<02:15, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/eat/qAF88xW4xPY_022.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 12/20 [02:25<01:35, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/what/_ZlZH4b0C44_025.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 13/20 [02:36<01:20, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/yes/q_p38s5JsXo_032.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 15/20 [03:00<00:59, 11.95s/it]OpenCV: Couldn't read video stream from file \"filtered_test/school/PsLiyUyrqds_003.mp4\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping unreadable video: filtered_test/school/PsLiyUyrqds_003.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/20 [03:24<00:35, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/fish/hUrfB8bikfw_027.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 18/20 [03:38<00:25, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/drink/OSPBKnsTuDY_012.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 19/20 [03:51<00:12, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping incomplete/broken video: filtered_test/orange/xEw0KrlJA6Q_029.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing filtered_test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [04:04<00:00, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Keypoint extraction complete!\n",
      "Saved files to: keypoints_top20_84/\n",
      "x_train shape: (634, 30, 84), y_train shape: (634,)\n",
      "x_test shape: (252, 30, 84), y_test shape: (252,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Settings ===\n",
    "train_dir = 'filtered_train'\n",
    "test_dir = 'filtered_test'\n",
    "output_folder = 'keypoints_top20_84'  # output folder for npy files\n",
    "frames_per_video = 30\n",
    "features_per_frame = 84  # 2 coordinates (x, y) Ã— 21 landmarks Ã— 2 hands\n",
    "\n",
    "# === Initialize Mediapipe Hands only ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)\n",
    "\n",
    "# === Helper: extract only (x, y) from both hands ===\n",
    "def extract_hand_keypoints(image):\n",
    "    result = hands.process(image)\n",
    "    keypoints = []\n",
    "\n",
    "    # Initialize empty hands\n",
    "    left_hand = None\n",
    "    right_hand = None\n",
    "\n",
    "    if result.multi_hand_landmarks and result.multi_handedness:\n",
    "        for idx, hand_landmarks in enumerate(result.multi_hand_landmarks):\n",
    "            handedness = result.multi_handedness[idx].classification[0].label\n",
    "            if handedness == \"Left\":\n",
    "                left_hand = hand_landmarks\n",
    "            elif handedness == \"Right\":\n",
    "                right_hand = hand_landmarks\n",
    "\n",
    "    # Extract left hand\n",
    "    if left_hand:\n",
    "        for lm in left_hand.landmark:\n",
    "            keypoints.extend([lm.x, lm.y])\n",
    "    else:\n",
    "        keypoints.extend([0] * 21 * 2)\n",
    "\n",
    "    # Extract right hand\n",
    "    if right_hand:\n",
    "        for lm in right_hand.landmark:\n",
    "            keypoints.extend([lm.x, lm.y])\n",
    "    else:\n",
    "        keypoints.extend([0] * 21 * 2)\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "# === Helper: process a folder (train/test) ===\n",
    "def process_folder(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    class_labels = os.listdir(folder_path)\n",
    "    label_to_index = {label: idx for idx, label in enumerate(sorted(class_labels))}\n",
    "\n",
    "    for label in tqdm(class_labels, desc=f\"Processing {folder_path}\"):\n",
    "        class_folder_path = os.path.join(folder_path, label)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "\n",
    "        for video_name in os.listdir(class_folder_path):\n",
    "            if not video_name.endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):\n",
    "                continue\n",
    "\n",
    "            video_path = os.path.join(class_folder_path, video_name)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"âš ï¸ Skipping unreadable video: {video_path}\")\n",
    "                continue\n",
    "\n",
    "            frames = []\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            frame_interval = max(1, total_frames // frames_per_video)\n",
    "\n",
    "            frame_idx = 0\n",
    "            while cap.isOpened() and len(frames) < frames_per_video:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                if frame_idx % frame_interval == 0:\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    keypoints = extract_hand_keypoints(frame_rgb)\n",
    "                    frames.append(keypoints)\n",
    "\n",
    "                frame_idx += 1\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "            # Only save sample if frames are complete and consistent\n",
    "            if len(frames) == frames_per_video and all(len(f) == features_per_frame for f in frames):\n",
    "                X.append(frames)\n",
    "                y.append(label_to_index[label])\n",
    "            else:\n",
    "                print(f\"âš ï¸ Skipping incomplete/broken video: {video_path}\")\n",
    "\n",
    "    return np.array(X), np.array(y), label_to_index\n",
    "\n",
    "# === Run extraction ===\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process train\n",
    "x_train, y_train, label_map_train = process_folder(train_dir)\n",
    "np.save(os.path.join(output_folder, 'x_train.npy'), x_train)\n",
    "np.save(os.path.join(output_folder, 'y_train.npy'), y_train)\n",
    "\n",
    "# Process test\n",
    "x_test, y_test, label_map_test = process_folder(test_dir)\n",
    "np.save(os.path.join(output_folder, 'x_test.npy'), x_test)\n",
    "np.save(os.path.join(output_folder, 'y_test.npy'), y_test)\n",
    "\n",
    "# Save label map\n",
    "import json\n",
    "with open(os.path.join(output_folder, 'label_map.json'), 'w') as f:\n",
    "    json.dump(label_map_train, f)\n",
    "\n",
    "print(\"\\nâœ… Keypoint extraction complete!\")\n",
    "print(f\"Saved files to: {output_folder}/\")\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6a3f5e-0130-4ae4-8802-83f079c54f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Training set class frequencies:\n",
      "fish       37\n",
      "milk       37\n",
      "eat        37\n",
      "nice       35\n",
      "teacher    33\n",
      "cousin     33\n",
      "sister     32\n",
      "water      32\n",
      "student    32\n",
      "white      32\n",
      "yes        31\n",
      "finish     30\n",
      "orange     30\n",
      "want       30\n",
      "what       29\n",
      "friend     29\n",
      "school     29\n",
      "no         29\n",
      "drink      29\n",
      "again      28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“Š Test set class frequencies:\n",
      "fish       14\n",
      "nice       14\n",
      "white      14\n",
      "milk       14\n",
      "finish     13\n",
      "want       13\n",
      "school     13\n",
      "eat        13\n",
      "orange     13\n",
      "no         13\n",
      "water      13\n",
      "student    12\n",
      "cousin     12\n",
      "yes        12\n",
      "teacher    12\n",
      "sister     12\n",
      "drink      12\n",
      "friend     11\n",
      "what       11\n",
      "again      11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Class frequencies saved to CSV files!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# === Load saved files ===\n",
    "y_train = np.load('keypoints_top20_84/y_train.npy')\n",
    "y_test = np.load('keypoints_top20_84/y_test.npy')\n",
    "\n",
    "with open('keypoints_top20_84/label_map.json', 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "# === Reverse the label_map\n",
    "index_to_label = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# === Count frequencies\n",
    "train_class_counts = pd.Series(y_train).map(index_to_label).value_counts()\n",
    "test_class_counts = pd.Series(y_test).map(index_to_label).value_counts()\n",
    "\n",
    "# === Show results\n",
    "print(\"\\nðŸ“Š Training set class frequencies:\")\n",
    "print(train_class_counts)\n",
    "\n",
    "print(\"\\nðŸ“Š Test set class frequencies:\")\n",
    "print(test_class_counts)\n",
    "\n",
    "# === Save to CSV if needed\n",
    "train_class_counts.to_csv('train_class_frequencies_after_extraction.csv')\n",
    "test_class_counts.to_csv('test_class_frequencies_after_extraction.csv')\n",
    "\n",
    "print(\"\\nâœ… Class frequencies saved to CSV files!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28771757-6ecd-4ad3-959c-e4a4f9527185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (signlang_env)",
   "language": "python",
   "name": "signlang_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
